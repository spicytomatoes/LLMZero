{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Elevator.py:8: UserWarning: cv2 is not installed: save_as_mp4 option will be disabled.\n",
      "  from pyRDDLGym.Visualizer.MovieGenerator import MovieGenerator\n",
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "#set path to folder above this\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from torch.distributions.categorical import Categorical\n",
    "from utils import live_plot\n",
    "from environments.ElevatorEnvironment import ElevatorEnvironment\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import tqdm\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Language based DQN network\n",
    "\n",
    "1. `all-mpnet-base-v2` as backbone to transform text state into latent state\n",
    "2. self-attention transformer layers to relevant attention information (since the embedding is not being trained)\n",
    "3. FFC to get q-values vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNLM(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder=None,\n",
    "                 embedding_dim=768,\n",
    "                 action_space_n=4,\n",
    "                 num_transformer_layers=1,\n",
    "                 fc_hidden_dims=[512, 256],\n",
    "                 ):\n",
    "        super(DQNLM, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "                \n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Transformer encoder layer (self-attention)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.embedding_dim, nhead=8, dim_feedforward=2048\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_transformer_layers)\n",
    "        \n",
    "        # Configurable fully connected layers for Q-values\n",
    "        fc_layers = []\n",
    "        input_dim = self.embedding_dim\n",
    "        for hidden_dim in fc_hidden_dims:\n",
    "            fc_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            fc_layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "        fc_layers.append(nn.Linear(input_dim, action_space_n))  # Output layer for Q-values\n",
    "        self.fc = nn.Sequential(*fc_layers)\n",
    "    \n",
    "    def forward(self, input_texts):\n",
    "        # Pass input texts through the SentenceTransformer encoder to get embeddings\n",
    "        # If encoder is None, assume input_texts are already embeddings\n",
    "        if self.encoder is not None and isinstance(input_texts, list):\n",
    "            with torch.no_grad():  # Freeze encoder during training\n",
    "                embeddings = self.encoder.encode(input_texts, convert_to_tensor=True)  # Shape: [batch_size, embedding_dim]\n",
    "        else:\n",
    "            embeddings = input_texts\n",
    "        \n",
    "        assert isinstance(embeddings, torch.Tensor), f\"Embeddings must be a PyTorch tensor, got: {type(embeddings)}, check encoder\"\n",
    "        assert embeddings.shape[1] == self.embedding_dim, f\"Embeddings must have shape [batch_size, embedding_dim], got: {embeddings.shape}\"\n",
    "        \n",
    "        # Reshape embeddings for the transformer encoder (add a sequence length of 1 for compatibility)\n",
    "        embeddings = embeddings.unsqueeze(0)  # Shape: [1, batch_size, embedding_dim]\n",
    "        \n",
    "        # Pass embeddings through the transformer encoder layer\n",
    "        transformer_output = self.transformer_encoder(embeddings)  # Shape: [1, batch_size, embedding_dim]\n",
    "        \n",
    "        # Remove the sequence length dimension\n",
    "        pooled_output = transformer_output.squeeze(0)  # Shape: [batch_size, embedding_dim]\n",
    "        \n",
    "        # Output Q-values\n",
    "        q_values = self.fc(pooled_output)  # Shape: [batch_size, num_actions]\n",
    "        return q_values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0232,  0.1813,  0.0450,  0.0037],\n",
      "        [-0.1898,  0.1318, -0.1481, -0.0193]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test inference\n",
    "model = DQNLM(action_space_n=4).to(\"cuda\")\n",
    "sentence_encoder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "input = [\"Hello, how are you?\", \"I am fine, thank you.\"]\n",
    "input_embeddings = sentence_encoder.encode(input, convert_to_tensor=True).to(\"cuda\")\n",
    "output = model(input_embeddings)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate pre-training data using expert agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples\\manifest.csv\n",
      "Available example environment(s):\n",
      "CartPole_continuous -> A simple continuous state-action MDP for the classical cart-pole system by Rich Sutton, with actions that describe the continuous force applied to the cart.\n",
      "CartPole_discrete -> A simple continuous state MDP for the classical cart-pole system by Rich Sutton, with discrete actions that apply a constant force on either the left or right side of the cart.\n",
      "Elevators -> The Elevator domain models evening rush hours when people from different floors in a building want to go down to the bottom floor using elevators.\n",
      "HVAC -> Multi-zone and multi-heater HVAC control problem\n",
      "MarsRover -> Multi Rover Navigation, where a group of agent needs to harvest mineral.\n",
      "MountainCar -> A simple continuous MDP for the classical mountain car control problem.\n",
      "NewLanguage -> Example with new language features.\n",
      "NewtonZero -> Example with Newton root-finding method.\n",
      "PowerGen_continuous -> A continuous simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PowerGen_discrete -> A simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PropDBN -> Simple propositional DBN.\n",
      "RaceCar -> A simple continuous MDP for the racecar problem.\n",
      "RecSim -> A problem of recommendation systems, with consumers and providers.\n",
      "Reservoir_continuous -> Continuous action version of management of the water level in interconnected reservoirs.\n",
      "Reservoir_discrete -> Discrete version of management of the water level in interconnected reservoirs.\n",
      "SupplyChain -> A supply chain with factory and multiple warehouses.\n",
      "SupplyChainNet -> A supply chain network with factory and multiple warehouses.\n",
      "Traffic -> BLX/QTM traffic model.\n",
      "UAV_continuous -> Continuous action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_discrete -> Discrete action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_mixed -> Mixed action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "Wildfire -> A boolean version of the wildfire fighting domain.\n",
      "The building has 5 floors and 1 elevators. Each floor has maximum 3 people waiting. Each elevator can carry maximum of 10 people.\n",
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples\\manifest.csv\n",
      "Available example environment(s):\n",
      "CartPole_continuous -> A simple continuous state-action MDP for the classical cart-pole system by Rich Sutton, with actions that describe the continuous force applied to the cart.\n",
      "CartPole_discrete -> A simple continuous state MDP for the classical cart-pole system by Rich Sutton, with discrete actions that apply a constant force on either the left or right side of the cart.\n",
      "Elevators -> The Elevator domain models evening rush hours when people from different floors in a building want to go down to the bottom floor using elevators.\n",
      "HVAC -> Multi-zone and multi-heater HVAC control problem\n",
      "MarsRover -> Multi Rover Navigation, where a group of agent needs to harvest mineral.\n",
      "MountainCar -> A simple continuous MDP for the classical mountain car control problem.\n",
      "NewLanguage -> Example with new language features.\n",
      "NewtonZero -> Example with Newton root-finding method.\n",
      "PowerGen_continuous -> A continuous simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PowerGen_discrete -> A simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PropDBN -> Simple propositional DBN.\n",
      "RaceCar -> A simple continuous MDP for the racecar problem.\n",
      "RecSim -> A problem of recommendation systems, with consumers and providers.\n",
      "Reservoir_continuous -> Continuous action version of management of the water level in interconnected reservoirs.\n",
      "Reservoir_discrete -> Discrete version of management of the water level in interconnected reservoirs.\n",
      "SupplyChain -> A supply chain with factory and multiple warehouses.\n",
      "SupplyChainNet -> A supply chain network with factory and multiple warehouses.\n",
      "Traffic -> BLX/QTM traffic model.\n",
      "UAV_continuous -> Continuous action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_discrete -> Discrete action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_mixed -> Mixed action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "Wildfire -> A boolean version of the wildfire fighting domain.\n",
      "The building has 5 floors and 1 elevators. Each floor has maximum 3 people waiting. Each elevator can carry maximum of 10 people.\n",
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples\\manifest.csv\n",
      "Available example environment(s):\n",
      "CartPole_continuous -> A simple continuous state-action MDP for the classical cart-pole system by Rich Sutton, with actions that describe the continuous force applied to the cart.\n",
      "CartPole_discrete -> A simple continuous state MDP for the classical cart-pole system by Rich Sutton, with discrete actions that apply a constant force on either the left or right side of the cart.\n",
      "Elevators -> The Elevator domain models evening rush hours when people from different floors in a building want to go down to the bottom floor using elevators.\n",
      "HVAC -> Multi-zone and multi-heater HVAC control problem\n",
      "MarsRover -> Multi Rover Navigation, where a group of agent needs to harvest mineral.\n",
      "MountainCar -> A simple continuous MDP for the classical mountain car control problem.\n",
      "NewLanguage -> Example with new language features.\n",
      "NewtonZero -> Example with Newton root-finding method.\n",
      "PowerGen_continuous -> A continuous simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PowerGen_discrete -> A simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PropDBN -> Simple propositional DBN.\n",
      "RaceCar -> A simple continuous MDP for the racecar problem.\n",
      "RecSim -> A problem of recommendation systems, with consumers and providers.\n",
      "Reservoir_continuous -> Continuous action version of management of the water level in interconnected reservoirs.\n",
      "Reservoir_discrete -> Discrete version of management of the water level in interconnected reservoirs.\n",
      "SupplyChain -> A supply chain with factory and multiple warehouses.\n",
      "SupplyChainNet -> A supply chain network with factory and multiple warehouses.\n",
      "Traffic -> BLX/QTM traffic model.\n",
      "UAV_continuous -> Continuous action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_discrete -> Discrete action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_mixed -> Mixed action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "Wildfire -> A boolean version of the wildfire fighting domain.\n",
      "The building has 5 floors and 1 elevators. Each floor has maximum 3 people waiting. Each elevator can carry maximum of 10 people.\n",
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples\\manifest.csv\n",
      "Available example environment(s):\n",
      "CartPole_continuous -> A simple continuous state-action MDP for the classical cart-pole system by Rich Sutton, with actions that describe the continuous force applied to the cart.\n",
      "CartPole_discrete -> A simple continuous state MDP for the classical cart-pole system by Rich Sutton, with discrete actions that apply a constant force on either the left or right side of the cart.\n",
      "Elevators -> The Elevator domain models evening rush hours when people from different floors in a building want to go down to the bottom floor using elevators.\n",
      "HVAC -> Multi-zone and multi-heater HVAC control problem\n",
      "MarsRover -> Multi Rover Navigation, where a group of agent needs to harvest mineral.\n",
      "MountainCar -> A simple continuous MDP for the classical mountain car control problem.\n",
      "NewLanguage -> Example with new language features.\n",
      "NewtonZero -> Example with Newton root-finding method.\n",
      "PowerGen_continuous -> A continuous simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PowerGen_discrete -> A simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PropDBN -> Simple propositional DBN.\n",
      "RaceCar -> A simple continuous MDP for the racecar problem.\n",
      "RecSim -> A problem of recommendation systems, with consumers and providers.\n",
      "Reservoir_continuous -> Continuous action version of management of the water level in interconnected reservoirs.\n",
      "Reservoir_discrete -> Discrete version of management of the water level in interconnected reservoirs.\n",
      "SupplyChain -> A supply chain with factory and multiple warehouses.\n",
      "SupplyChainNet -> A supply chain network with factory and multiple warehouses.\n",
      "Traffic -> BLX/QTM traffic model.\n",
      "UAV_continuous -> Continuous action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_discrete -> Discrete action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_mixed -> Mixed action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "Wildfire -> A boolean version of the wildfire fighting domain.\n",
      "The building has 5 floors and 1 elevators. Each floor has maximum 3 people waiting. Each elevator can carry maximum of 10 people.\n",
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples\\manifest.csv\n",
      "Available example environment(s):\n",
      "CartPole_continuous -> A simple continuous state-action MDP for the classical cart-pole system by Rich Sutton, with actions that describe the continuous force applied to the cart.\n",
      "CartPole_discrete -> A simple continuous state MDP for the classical cart-pole system by Rich Sutton, with discrete actions that apply a constant force on either the left or right side of the cart.\n",
      "Elevators -> The Elevator domain models evening rush hours when people from different floors in a building want to go down to the bottom floor using elevators.\n",
      "HVAC -> Multi-zone and multi-heater HVAC control problem\n",
      "MarsRover -> Multi Rover Navigation, where a group of agent needs to harvest mineral.\n",
      "MountainCar -> A simple continuous MDP for the classical mountain car control problem.\n",
      "NewLanguage -> Example with new language features.\n",
      "NewtonZero -> Example with Newton root-finding method.\n",
      "PowerGen_continuous -> A continuous simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PowerGen_discrete -> A simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PropDBN -> Simple propositional DBN.\n",
      "RaceCar -> A simple continuous MDP for the racecar problem.\n",
      "RecSim -> A problem of recommendation systems, with consumers and providers.\n",
      "Reservoir_continuous -> Continuous action version of management of the water level in interconnected reservoirs.\n",
      "Reservoir_discrete -> Discrete version of management of the water level in interconnected reservoirs.\n",
      "SupplyChain -> A supply chain with factory and multiple warehouses.\n",
      "SupplyChainNet -> A supply chain network with factory and multiple warehouses.\n",
      "Traffic -> BLX/QTM traffic model.\n",
      "UAV_continuous -> Continuous action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_discrete -> Discrete action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_mixed -> Mixed action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "Wildfire -> A boolean version of the wildfire fighting domain.\n",
      "The building has 5 floors and 1 elevators. Each floor has maximum 3 people waiting. Each elevator can carry maximum of 10 people.\n",
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples\\manifest.csv\n",
      "Available example environment(s):\n",
      "CartPole_continuous -> A simple continuous state-action MDP for the classical cart-pole system by Rich Sutton, with actions that describe the continuous force applied to the cart.\n",
      "CartPole_discrete -> A simple continuous state MDP for the classical cart-pole system by Rich Sutton, with discrete actions that apply a constant force on either the left or right side of the cart.\n",
      "Elevators -> The Elevator domain models evening rush hours when people from different floors in a building want to go down to the bottom floor using elevators.\n",
      "HVAC -> Multi-zone and multi-heater HVAC control problem\n",
      "MarsRover -> Multi Rover Navigation, where a group of agent needs to harvest mineral.\n",
      "MountainCar -> A simple continuous MDP for the classical mountain car control problem.\n",
      "NewLanguage -> Example with new language features.\n",
      "NewtonZero -> Example with Newton root-finding method.\n",
      "PowerGen_continuous -> A continuous simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PowerGen_discrete -> A simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PropDBN -> Simple propositional DBN.\n",
      "RaceCar -> A simple continuous MDP for the racecar problem.\n",
      "RecSim -> A problem of recommendation systems, with consumers and providers.\n",
      "Reservoir_continuous -> Continuous action version of management of the water level in interconnected reservoirs.\n",
      "Reservoir_discrete -> Discrete version of management of the water level in interconnected reservoirs.\n",
      "SupplyChain -> A supply chain with factory and multiple warehouses.\n",
      "SupplyChainNet -> A supply chain network with factory and multiple warehouses.\n",
      "Traffic -> BLX/QTM traffic model.\n",
      "UAV_continuous -> Continuous action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_discrete -> Discrete action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_mixed -> Mixed action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "Wildfire -> A boolean version of the wildfire fighting domain.\n",
      "The building has 5 floors and 1 elevators. Each floor has maximum 3 people waiting. Each elevator can carry maximum of 10 people.\n",
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples\\manifest.csv\n",
      "Available example environment(s):\n",
      "CartPole_continuous -> A simple continuous state-action MDP for the classical cart-pole system by Rich Sutton, with actions that describe the continuous force applied to the cart.\n",
      "CartPole_discrete -> A simple continuous state MDP for the classical cart-pole system by Rich Sutton, with discrete actions that apply a constant force on either the left or right side of the cart.\n",
      "Elevators -> The Elevator domain models evening rush hours when people from different floors in a building want to go down to the bottom floor using elevators.\n",
      "HVAC -> Multi-zone and multi-heater HVAC control problem\n",
      "MarsRover -> Multi Rover Navigation, where a group of agent needs to harvest mineral.\n",
      "MountainCar -> A simple continuous MDP for the classical mountain car control problem.\n",
      "NewLanguage -> Example with new language features.\n",
      "NewtonZero -> Example with Newton root-finding method.\n",
      "PowerGen_continuous -> A continuous simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PowerGen_discrete -> A simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PropDBN -> Simple propositional DBN.\n",
      "RaceCar -> A simple continuous MDP for the racecar problem.\n",
      "RecSim -> A problem of recommendation systems, with consumers and providers.\n",
      "Reservoir_continuous -> Continuous action version of management of the water level in interconnected reservoirs.\n",
      "Reservoir_discrete -> Discrete version of management of the water level in interconnected reservoirs.\n",
      "SupplyChain -> A supply chain with factory and multiple warehouses.\n",
      "SupplyChainNet -> A supply chain network with factory and multiple warehouses.\n",
      "Traffic -> BLX/QTM traffic model.\n",
      "UAV_continuous -> Continuous action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_discrete -> Discrete action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_mixed -> Mixed action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "Wildfire -> A boolean version of the wildfire fighting domain.\n",
      "The building has 5 floors and 1 elevators. Each floor has maximum 3 people waiting. Each elevator can carry maximum of 10 people.\n",
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples\\manifest.csv\n",
      "Available example environment(s):\n",
      "CartPole_continuous -> A simple continuous state-action MDP for the classical cart-pole system by Rich Sutton, with actions that describe the continuous force applied to the cart.\n",
      "CartPole_discrete -> A simple continuous state MDP for the classical cart-pole system by Rich Sutton, with discrete actions that apply a constant force on either the left or right side of the cart.\n",
      "Elevators -> The Elevator domain models evening rush hours when people from different floors in a building want to go down to the bottom floor using elevators.\n",
      "HVAC -> Multi-zone and multi-heater HVAC control problem\n",
      "MarsRover -> Multi Rover Navigation, where a group of agent needs to harvest mineral.\n",
      "MountainCar -> A simple continuous MDP for the classical mountain car control problem.\n",
      "NewLanguage -> Example with new language features.\n",
      "NewtonZero -> Example with Newton root-finding method.\n",
      "PowerGen_continuous -> A continuous simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PowerGen_discrete -> A simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PropDBN -> Simple propositional DBN.\n",
      "RaceCar -> A simple continuous MDP for the racecar problem.\n",
      "RecSim -> A problem of recommendation systems, with consumers and providers.\n",
      "Reservoir_continuous -> Continuous action version of management of the water level in interconnected reservoirs.\n",
      "Reservoir_discrete -> Discrete version of management of the water level in interconnected reservoirs.\n",
      "SupplyChain -> A supply chain with factory and multiple warehouses.\n",
      "SupplyChainNet -> A supply chain network with factory and multiple warehouses.\n",
      "Traffic -> BLX/QTM traffic model.\n",
      "UAV_continuous -> Continuous action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_discrete -> Discrete action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_mixed -> Mixed action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "Wildfire -> A boolean version of the wildfire fighting domain.\n",
      "The building has 5 floors and 1 elevators. Each floor has maximum 3 people waiting. Each elevator can carry maximum of 10 people.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('num-person-waiting___f0',\n",
       "               array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)),\n",
       "              ('num-person-waiting___f1',\n",
       "               array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)),\n",
       "              ('num-person-waiting___f2',\n",
       "               array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)),\n",
       "              ('num-person-waiting___f3',\n",
       "               array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)),\n",
       "              ('num-person-waiting___f4',\n",
       "               array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)),\n",
       "              ('num-person-in-elevator___e0',\n",
       "               array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)),\n",
       "              ('elevator-dir-up___e0',\n",
       "               array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)),\n",
       "              ('elevator-closed___e0',\n",
       "               array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)),\n",
       "              ('elevator-at-floor___e0__f0',\n",
       "               array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)),\n",
       "              ('elevator-at-floor___e0__f1',\n",
       "               array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)),\n",
       "              ('elevator-at-floor___e0__f2',\n",
       "               array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)),\n",
       "              ('elevator-at-floor___e0__f3',\n",
       "               array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)),\n",
       "              ('elevator-at-floor___e0__f4',\n",
       "               array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int64))]),\n",
       " {})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def create_env():\n",
    "#     env = ElevatorEnvironment()\n",
    "#     env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "    \n",
    "#     return env\n",
    "\n",
    "# batch_size = 8\n",
    "# envs = gym.vector.SyncVectorEnv([lambda: create_env() for _ in range(batch_size)])\n",
    "# envs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples\\manifest.csv\n",
      "Available example environment(s):\n",
      "CartPole_continuous -> A simple continuous state-action MDP for the classical cart-pole system by Rich Sutton, with actions that describe the continuous force applied to the cart.\n",
      "CartPole_discrete -> A simple continuous state MDP for the classical cart-pole system by Rich Sutton, with discrete actions that apply a constant force on either the left or right side of the cart.\n",
      "Elevators -> The Elevator domain models evening rush hours when people from different floors in a building want to go down to the bottom floor using elevators.\n",
      "HVAC -> Multi-zone and multi-heater HVAC control problem\n",
      "MarsRover -> Multi Rover Navigation, where a group of agent needs to harvest mineral.\n",
      "MountainCar -> A simple continuous MDP for the classical mountain car control problem.\n",
      "NewLanguage -> Example with new language features.\n",
      "NewtonZero -> Example with Newton root-finding method.\n",
      "PowerGen_continuous -> A continuous simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PowerGen_discrete -> A simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PropDBN -> Simple propositional DBN.\n",
      "RaceCar -> A simple continuous MDP for the racecar problem.\n",
      "RecSim -> A problem of recommendation systems, with consumers and providers.\n",
      "Reservoir_continuous -> Continuous action version of management of the water level in interconnected reservoirs.\n",
      "Reservoir_discrete -> Discrete version of management of the water level in interconnected reservoirs.\n",
      "SupplyChain -> A supply chain with factory and multiple warehouses.\n",
      "SupplyChainNet -> A supply chain network with factory and multiple warehouses.\n",
      "Traffic -> BLX/QTM traffic model.\n",
      "UAV_continuous -> Continuous action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_discrete -> Discrete action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_mixed -> Mixed action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "Wildfire -> A boolean version of the wildfire fighting domain.\n",
      "The building has 5 floors and 1 elevators. Each floor has maximum 3 people waiting. Each elevator can carry maximum of 10 people.\n"
     ]
    }
   ],
   "source": [
    "env = ElevatorEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [03:47<00:00, 440.12it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# get expert agent\n",
    "from agents.elevator_expert import ElevatorExpertPolicyAgent\n",
    "\n",
    "agent = ElevatorExpertPolicyAgent()\n",
    "\n",
    "# generate expert trajectories\n",
    "num_trajectories = 100000\n",
    "\n",
    "trajectories = []\n",
    "\n",
    "state, _ = env.reset()\n",
    "\n",
    "num_episodes = 0\n",
    "\n",
    "for _ in tqdm.tqdm(range(num_trajectories)):\n",
    "    state_text = env.state_to_text(state)\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done, _, _ = env.step(action)\n",
    "    next_state_text = env.state_to_text(next_state)\n",
    "    \n",
    "    trajectories.append((num_episodes, state_text, action, reward, next_state_text, done))\n",
    "    \n",
    "    if done:\n",
    "        state, _ = env.reset()\n",
    "        num_episodes += 1\n",
    "    else:\n",
    "        state = next_state\n",
    "        \n",
    "# save trajectories\n",
    "import pickle\n",
    "\n",
    "with open(\"trajectories/expert_trajectories.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trajectories, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 782/782 [05:12<00:00,  2.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trajectories\n",
    "trajectories = pickle.load(open(\"trajectories/expert_trajectories.pkl\", \"rb\"))\n",
    "trajectories[0]\n",
    "\n",
    "# we first pretrain the DQN model to follow the expert policy\n",
    "# we need state as input action as output\n",
    "\n",
    "states = [t[1] for t in trajectories]\n",
    "actions = [t[2] for t in trajectories]\n",
    "\n",
    "sentence_encoder = sentence_encoder.to(\"cuda\")\n",
    "states_tensor = sentence_encoder.encode(states, batch_size=128, convert_to_tensor=True, show_progress_bar=True)\n",
    "states_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode action into one-hot and convert to tensor\n",
    "actions_tensor = torch.tensor(actions, dtype=torch.long).to(\"cuda\")\n",
    "actions_tensor = F.one_hot(actions_tensor, num_classes=4).float()\n",
    "actions_tensor.shape    # [num_trajectories, num_actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat state action pairs and save to tensor_data/\n",
    "torch.save((states_tensor, actions_tensor), \"tensor_data/expert_state_action_pairs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and dataloader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "dataset = TensorDataset(states_tensor, actions_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = DQNLM(encoder=sentence_encoder, action_space_n=4).to(\"cuda\")\n",
    "\n",
    "# create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# create loss function for multi-class classification\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3125 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 768]) torch.Size([32, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() of a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(states_batch\u001b[38;5;241m.\u001b[39mshape, actions_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 13\u001b[0m q_values \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(q_values, actions_batch)\n\u001b[0;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[7], line 36\u001b[0m, in \u001b[0;36mDQNLM.forward\u001b[1;34m(self, input_texts)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Freeze encoder during training\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: [batch_size, embedding_dim]\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m input_texts\n",
      "File \u001b[1;32mc:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:584\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    583\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 584\u001b[0m length_sorted_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_text_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msen\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    585\u001b[0m sentences_sorted \u001b[38;5;241m=\u001b[39m [sentences[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m length_sorted_idx]\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n",
      "File \u001b[1;32mc:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:584\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    583\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 584\u001b[0m length_sorted_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort([\u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_text_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sentences])\n\u001b[0;32m    585\u001b[0m sentences_sorted \u001b[38;5;241m=\u001b[39m [sentences[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m length_sorted_idx]\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n",
      "File \u001b[1;32mc:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1462\u001b[0m, in \u001b[0;36mSentenceTransformer._text_length\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text)\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1462\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text)\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28mlen\u001b[39m(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text])\n",
      "File \u001b[1;32mc:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\torch\\_tensor.py:1087\u001b[0m, in \u001b[0;36mTensor.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen() of a 0-d tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[0;32m   1089\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1090\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing len to get tensor shape might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1091\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommended usage would be tensor.shape[0]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1095\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1096\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: len() of a 0-d tensor"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# train model for 1 epoch\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm.tqdm(dataloader, total=len(dataloader))\n",
    "    \n",
    "    for states_batch, actions_batch in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        print(states_batch.shape, actions_batch.shape)\n",
    "        q_values = model(states_batch)\n",
    "        loss = loss_fn(q_values, actions_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_description(f\"Loss: {total_loss:.4f}\")\n",
    "        \n",
    "        data_to_plot = {\n",
    "            \"loss\": loss.item()\n",
    "        }\n",
    "        \n",
    "        break\n",
    "        \n",
    "        live_plot(data_to_plot)\n",
    "        \n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiplanning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
