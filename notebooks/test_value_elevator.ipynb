{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Elevator.py:8: UserWarning: cv2 is not installed: save_as_mp4 option will be disabled.\n",
      "  from pyRDDLGym.Visualizer.MovieGenerator import MovieGenerator\n",
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from environments.ElevatorEnvironment import ElevatorEnvironment\n",
    "from agents.llmzero import LLMTransitionModel\n",
    "from agents.random_agent import RandomAgent\n",
    "from agents.elevator_expert import ElevatorExpertPolicyAgent\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Examples\\manifest.csv\n",
      "Available example environment(s):\n",
      "CartPole_continuous -> A simple continuous state-action MDP for the classical cart-pole system by Rich Sutton, with actions that describe the continuous force applied to the cart.\n",
      "CartPole_discrete -> A simple continuous state MDP for the classical cart-pole system by Rich Sutton, with discrete actions that apply a constant force on either the left or right side of the cart.\n",
      "Elevators -> The Elevator domain models evening rush hours when people from different floors in a building want to go down to the bottom floor using elevators.\n",
      "HVAC -> Multi-zone and multi-heater HVAC control problem\n",
      "MarsRover -> Multi Rover Navigation, where a group of agent needs to harvest mineral.\n",
      "MountainCar -> A simple continuous MDP for the classical mountain car control problem.\n",
      "NewLanguage -> Example with new language features.\n",
      "NewtonZero -> Example with Newton root-finding method.\n",
      "PowerGen_continuous -> A continuous simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PowerGen_discrete -> A simple power generation problem loosely modeled on the problem of unit commitment.\n",
      "PropDBN -> Simple propositional DBN.\n",
      "RaceCar -> A simple continuous MDP for the racecar problem.\n",
      "RecSim -> A problem of recommendation systems, with consumers and providers.\n",
      "Reservoir_continuous -> Continuous action version of management of the water level in interconnected reservoirs.\n",
      "Reservoir_discrete -> Discrete version of management of the water level in interconnected reservoirs.\n",
      "SupplyChain -> A supply chain with factory and multiple warehouses.\n",
      "SupplyChainNet -> A supply chain network with factory and multiple warehouses.\n",
      "Traffic -> BLX/QTM traffic model.\n",
      "UAV_continuous -> Continuous action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_discrete -> Discrete action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "UAV_mixed -> Mixed action space version of multi-UAV problem where a group of UAVs have to reach goal positions in the 3d Space.\n",
      "Wildfire -> A boolean version of the wildfire fighting domain.\n",
      "The building has 5 floors and 1 elevators. Each floor has maximum 3 people waiting. Each elevator can carry maximum of 10 people.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianch\\miniconda3\\envs\\aiplanning\\Lib\\site-packages\\pyRDDLGym\\Core\\Env\\RDDLConstraints.py:85: UserWarning: Constraint does not have a structure of <action or state fluent> <op> <rhs>, where:\n",
      "<op> is one of {<=, <, >=, >}\n",
      "<rhs> is a deterministic function of non-fluents or constants only.\n",
      ">> ( sum_{?f: floor} [ elevator-at-floor(?e, ?f) ] ) == 1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = ElevatorEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 117\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_agent = RandomAgent(env, seed=SEED)\n",
    "expert_agent = ElevatorExpertPolicyAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,0,-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import elevator_estimate_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset(seed=SEED)\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'num-person-waiting___f0': 0,\n",
       "  'num-person-waiting___f1': 0,\n",
       "  'num-person-waiting___f2': 0,\n",
       "  'num-person-waiting___f3': 1,\n",
       "  'num-person-waiting___f4': 0,\n",
       "  'num-person-in-elevator___e0': 0,\n",
       "  'elevator-dir-up___e0': True,\n",
       "  'elevator-closed___e0': True,\n",
       "  'elevator-at-floor___e0__f0': True,\n",
       "  'elevator-at-floor___e0__f1': False,\n",
       "  'elevator-at-floor___e0__f2': False,\n",
       "  'elevator-at-floor___e0__f3': False,\n",
       "  'elevator-at-floor___e0__f4': False},\n",
       " [0, 0, 0])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, _, _, _, _ = env.step(0)\n",
    "history.append(0)\n",
    "state, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.mcts import MCTSAgent\n",
    "\n",
    "mcts_args = {\n",
    "            \"num_simulations\": 100,\n",
    "            \"c_puct\": 150,    #should be proportional to the scale of the rewards \n",
    "            \"gamma\": 0.95,\n",
    "            \"max_depth\": 100,\n",
    "            \"num_rollouts\": 10,\n",
    "            \"backprop_T\": 50,\n",
    "        }\n",
    "# agent = MCTSAgent(env, policy=llm_agent, debug=True, args=mcts_args)\n",
    "agent = MCTSAgent(env, policy=None, debug=True, args=mcts_args)\n",
    "\n",
    "state, _ = env.reset(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 0: Q = 120.29809079607519, N = 91\n",
      "Action 1: Q = 3.1199280561144924, N = 3\n",
      "Action 2: Q = 7.514551138807625, N = 3\n",
      "Action 3: Q = 7.514551138807625, N = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "action = agent.act(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiplanning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
