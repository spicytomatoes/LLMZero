{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlenovo/CS5242Proj/LLMZero/venv/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from agents.alfworld_llm_policy import ALFWorldLLMPolicyAgent\n",
    "from environments.ALFWorldEnvironment import ALFWorldEnvironment\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=os.getenv(\"CUSTOM_BASE_URL\"),\n",
    "    api_key=os.getenv(\"CUSTOM_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(system_prompt, user_prompt, model):\n",
    "    '''\n",
    "    Query the LLM with the user prompt\n",
    "    '''\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            response = client.chat.completions.create(model=model, messages=messages)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling API: {e}, retrying...\")\n",
    "            time.sleep(1)\n",
    "    \n",
    "    # grab the content of the first choice (only one choice is returned)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def save_to_file(response):\n",
    "    with open('output_logs.txt', 'a') as logs:\n",
    "        print('----------------------------------------', file=logs)\n",
    "        print(response, file=logs)\n",
    "    \n",
    "def get_user_prompt(state, action):\n",
    "    user_prompt = \"**Current State:**\\n\"\n",
    "    user_prompt += state\n",
    "    user_prompt += \"\\n**Action:**\"\n",
    "    user_prompt += action\n",
    "    user_prompt += \"\\n\"\n",
    "    return user_prompt\n",
    "\n",
    "def extract_state(response: str):\n",
    "    '''\n",
    "    Extract the next state from the LLM response\n",
    "    '''\n",
    "    extract_state_regex = r\"next state:(.*?)```\"\n",
    "    extract_state_regex_fallback = [r\"\\*\\*next state:\\*\\*(.*)\", r\"next state:(.*)\"]\n",
    "    \n",
    "    match = re.search(extract_state_regex, response, re.DOTALL | re.IGNORECASE)\n",
    "    if match is not None:\n",
    "        next_state = match.group(1)\n",
    "        return next_state, \"success\"\n",
    "    else:\n",
    "        # if debug:\n",
    "        #     print(\"Warning: No match found, trying fallback regex...\")\n",
    "        \n",
    "        for regex in extract_state_regex_fallback:\n",
    "            match = re.search(regex, response, re.DOTALL | re.IGNORECASE)\n",
    "            if match is not None:\n",
    "                next_state = match.group(1)\n",
    "                return next_state, \"success on fallback regex\"\n",
    "        else:\n",
    "            print(\"Error: No match found with fallback regex, using full response as next state\")\n",
    "            return response, \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'open-mixtral-8x22b'\n",
    "# model = 'mistral-large-2407'\n",
    "\n",
    "with open('../prompts/prompt_alfworld_transition.txt', 'r') as f:\n",
    "    system_prompt = f.read()\n",
    "\n",
    "state = \"You arrive at desk 1. On the desk 1, you see a book 1, a notepad 1, a pen 1, and a pencil 1.\"\n",
    "action = \"take book 1 from desk 1\"\n",
    "user_prompt = get_user_prompt(state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Reasoning**\n",
      "The given action follows the action format for **Pick up an Object**. Thus, in the next state, we expect the agent to pick up the book 1 from desk 1.\n",
      "\n",
      "```plaintext\n",
      "Next State:\n",
      "You pick up the book 1 from the desk 1.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = query_llm(system_prompt, user_prompt, model)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing AlfredTWEnv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 416.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall we have 1 games in split=train\n",
      "Training with 1 games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State:  -= Welcome to TextWorld, ALFRED! =-\n",
      "\n",
      "You are in the middle of a room. Looking quickly around you, you see a bed 1, a desk 1, a drawer 3, a drawer 2, a drawer 1, a garbagecan 1, a laundryhamper 1, a shelf 2, a shelf 1, and a sidetable 1.\n",
      "\n",
      "Your task is to: put a alarmclock in desk.\n",
      "Action:  go to sidetable 1\n",
      "Predicted Next State \n",
      "You arrive at sidetable 1. On the sidetable 1, you see a alarmclock 1.\n",
      "\n",
      "Actual Next State You arrive at loc 20. On the sidetable 1, you see a alarmclock 3, a alarmclock 2, a alarmclock 1, a creditcard 1, a desklamp 1, a keychain 1, a pen 3, a pen 2, and a pencil 3.\n",
      "-----------------------------\n",
      "\n",
      "Action:  take alarmclock 1 from sidetable 1\n",
      "Predicted Next State \n",
      "You pick up the alarmclock 1 from the sidetable 1.\n",
      "\n",
      "Actual Next State You pick up the alarmclock 1 from the sidetable 1.\n",
      "-----------------------------\n",
      "\n",
      "Action:  put alarmclock 1 in/on sidetable 1\n",
      "Predicted Next State \n",
      "You put the alarmclock 1 on the sidetable 1.\n",
      "\n",
      "Actual Next State You put the alarmclock 1 in/on the sidetable 1.\n",
      "-----------------------------\n",
      "\n",
      "Action:  take alarmclock 1 from sidetable 1\n",
      "Predicted Next State **\n",
      "Next state: You pick up the alarmclock 1 from the sidetable 1.\n",
      "Actual Next State You pick up the alarmclock 1 from the sidetable 1.\n",
      "-----------------------------\n",
      "\n",
      "Action:  put alarmclock 1 in/on sidetable 1\n",
      "Predicted Next State \n",
      "You put the alarmclock 1 on the sidetable 1.\n",
      "\n",
      "Actual Next State You put the alarmclock 1 in/on the sidetable 1.\n",
      "-----------------------------\n",
      "\n",
      "Action:  take alarmclock 1 from sidetable 1\n",
      "Predicted Next State \n",
      "You pick up the alarmclock 1 from the sidetable 1.\n",
      "Actual Next State You pick up the alarmclock 1 from the sidetable 1.\n",
      "-----------------------------\n",
      "\n",
      "Action:  put alarmclock 1 in/on sidetable 1\n",
      "Predicted Next State \n",
      "You put the alarmclock 1 in/on the sidetable 1.\n",
      "Actual Next State You put the alarmclock 1 in/on the sidetable 1.\n",
      "-----------------------------\n",
      "\n",
      "Action:  take alarmclock 1 from sidetable 1\n",
      "Predicted Next State \n",
      "Nothing happens.\n",
      "\n",
      "Actual Next State You pick up the alarmclock 1 from the sidetable 1.\n",
      "-----------------------------\n",
      "\n",
      "Action:  put alarmclock 1 in/on sidetable 1\n",
      "Predicted Next State \n",
      "You put the alarmclock 1 on the sidetable 1.\n",
      "\n",
      "Actual Next State You put the alarmclock 1 in/on the sidetable 1.\n",
      "-----------------------------\n",
      "\n",
      "Action:  take alarmclock 1 from sidetable 1\n",
      "Predicted Next State \n",
      "You pick up the alarmclock 1 from the sidetable 1.\n",
      "\n",
      "Actual Next State You pick up the alarmclock 1 from the sidetable 1.\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = ALFWorldEnvironment(config_path='../configs/alfworld_env.yaml')\n",
    "agent = ALFWorldLLMPolicyAgent(env, device='cuda', llm_model='gpt-4o-mini', prompt_buffer_prefix=\"alfworld\", env_params={ \"system_prompt_path\": \"../prompts/prompt_alfworld_policy.txt\" })\n",
    "\n",
    "obs, _ = env.reset()\n",
    "state = obs\n",
    "print('Initial State: ', state['text_state'])\n",
    "\n",
    "num_steps = 10\n",
    "for _ in range(num_steps):\n",
    "    action = agent.act(state)\n",
    "    print('Action: ', action)\n",
    "\n",
    "    user_prompt = get_user_prompt(state['text_state'], action)\n",
    "    pred_state = query_llm(system_prompt, user_prompt, model)\n",
    "    pred_state, _ = extract_state(pred_state)\n",
    "    print('Predicted Next State', pred_state)\n",
    "\n",
    "    state, reward, done, _, info = env.step(action)\n",
    "    print('Actual Next State', state['text_state'])\n",
    "    print('-----------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
